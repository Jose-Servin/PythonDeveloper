# Next Level Python Course

Resources:

* [Link to course](https://academy.arjancodes.com/next-level-python)
* [Source Code](../Projects/NextLevelPython/)

## Static Typing

In static typing, variables are explicitly declared with their data types at compile time, and the type checking is performed at compile time.
Once a variable is declared with a specific data type, it cannot hold values of any other type. This restriction helps catch type-related errors early in the development process.
Examples of statically typed languages include Java, C, C++, and Swift.

## Dynamic Typing

In dynamic typing, variables are not bound to a specific data type at compile time. Instead, the type of a variable is determined at runtime based on the value assigned to it.
Type checking is typically performed at runtime, as opposed to compile time. This means that type errors might only be discovered while the program is running.
Dynamic typing provides more flexibility as variables can hold values of any type and can change their type during runtime.
Examples of dynamically typed languages include Python, JavaScript, and Ruby.

## Duck Typing In Python

In Python, instead of checking if an object belongs to a specific class or type, you check if it supports certain methods or behaviors. If an object implements the necessary methods or attributes, it can be used in a particular context, regardless of its actual type or class.

In `../Projects/NextLevelPython/duck_typing.py` we see the `len()` function expects an Object of type `Sized` which means this Object needs to have a `__len__()` dunder method.

[In other words](https://www.pythonmorsels.com/making-the-len-function-work-on-your-python-objects/):

```text
Python's built-in len function calls the __len__ method (pronounced "dunder len") on the object you give it.

So if that object has a __len__ method, it has a length.
```

## Type Annotations

### Type Annotations in Python: Basic to Advanced

It's easy to add type hints in Python, we simply use the `:` and declare what type our variable is/what variables it's made of.

```python
my_str: str = "Hello World"
my_list: list[int] = [34, 54, 65, 78]
my_dict: dict[str, int] = {"one": 123, "two": 456, "three": 789}
```

For instances where we provide the "wrong" type hint, we won't see an error because python does not execute type hints. We must remember that type hints are for the Developer to debug and understand variable requirements.

We can use `strict` type checking mode in VSCode by adding the following setting in our workspace.json file. See [VSCode Docs](https://code.visualstudio.com/docs/python/settings-reference#_python-language-server-settings)

```json
"settings":
    {
        "python.analysis.typeCheckingMode": "strict"
    }
```

We can also leverage the union type syntax which allows us to declare "or" statements when specifying type hints. We can see this in the `protocol_before.py` `EmailClient` class initializer.

```python
class EmailClient:
    def __init__(
        self,
        login: str | None = None,
        password: str | None = None,
        name: str | None = None,
        to_address: str = DEFAULT_EMAIL,
    ):
```

### Duck Typing with Protocol Class

"A protocol is a set of methods or attributes that an object must have in order to be considered compatible with that protocol. Protocols enable you to define interfaces without explicitly creating a class or inheriting from a specific base class."

[Reference Link](https://dev.to/shameerchagani/what-is-a-protocol-in-python-3fl1)

To understand this, we will look at `../Projects/NextLevelPython/protocol_before.py`. This file contains an `EmailClient` class which represents the scaffold for a basic email sending system. The breakdown is very simple:

1. Initializer captures user information.
2. Create `SMTP` server and log in using user provided credentials.
3. Build Connect and Quit server connections methods.
4. Build a Send Email method that calls the `SMTP` methods defined previously.

Now, the way we've developed this `EmailClient` functionality has created a dependency between our custom `EmailClient` class and the library which provides the `SMTP`.

To remove this dependency and improve our `EmailClient` implementation we use a `Protocol` class. Here, we will specify the structure of the object we should expect, i.e the structure our `self._server` should have and not worry about specifics.

The file, `../Projects/NextLevelPython/protocol_after.py` contains the `Protocol` implementation.

We first start by defining the "Protocol" an `EmailServer` should follow.

```python
from typing import Protocol

DEFAULT_EMAIL = "support@arjancodes.com"
LOGIN = "admin"
PASSWORD = "admin"


class EmailServer(Protocol):
    @property
    def _host(self) -> str: ...

    def connect(self, host: str, port: int) -> None: ...

    def starttls(self) -> None: ...

    def login(self, login: str, password: str) -> None: ...

    def quit(self) -> None: ...

    def sendmail(self, from_address: str, to_address: str,
                 message: str) -> None: ...

```

And now, we pass this `EmailServer` protocol as the instance type of the `smtp_server` used in our `EmailClient`.

```python
class EmailClient:
    def __init__(
        self,
        smtp_server: EmailServer,
        login: str | None = None,
        password: str | None = None,
        name: str | None = None,
        to_address: str = DEFAULT_EMAIL,
    ):
```

So now, when we initialize our `EmailClient` we pass whatever `SMTP` server instance we want to use - as long as that instance contains the methods in our `EmailServer` protocol. This works because we've provided the Protocol as the type for this `smtp_server` which is provided to our `EmailClient` in the initializer. This is called Dependency Injection; [learn more about this](https://www.youtube.com/watch?v=fhwhQjY2GCY&ab_channel=ArjanCodes)

## Next-Level Classes

### Intro to DataClasses

To understand dataclasses, we'll first take a look at a simple `Person` class definition.

```python
import random
import string

def generate_id() -> str:
    return "".join(random.choices(string.ascii_uppercase, k=12))


class Person:
    def __init__(self, name: str, address: str):
        self.id = generate_id()
        self.name = name
        self.address = address
        self.email_addresses = []


def main() -> None:
    person = Person(name="John", address="123 Main St")
    print(person)


if __name__ == "__main__":
    main()

```

We can represent this same `Person` object with a dataclass. However, there is some debate about the usage of a dataclass where some argue a dataclass should instead represent, data. That is pointers, arrays, coordinates etc.

So, to convert this `Person` to a dataclass we do the following:

```python
import random
import string
from dataclasses import dataclass, field


def generate_id() -> str:
    return "".join(random.choices(string.ascii_uppercase, k=12))


@dataclass
class Person:
    name: str
    address: str
    active: bool = True
    email_addresses: list[str] = field(default_factory=list)
    id: str = field(init=False, default_factory=generate_id)
    _search_string: str = field(init=False, repr=False)

    def __post_init__(self):
        self._search_string = f"{self.name} {self.address}"


def main() -> None:
    person = Person(name="John", address="123 Main St")
    print(person)


if __name__ == "__main__":
    main()
```

### Understanding our Person Dataclass

If we move this to a file called `person_dataclass.py` and run, we'll see that dataclasses takes care of the `__repr__` dunder method and we get a useful print of this person instance we created. More specifically, this is done by automatically implementing the `__repr__(self):` dunder method.

```terminal
Person(name='John', address='123 Main St', active=True, email_addresses=[], id='AHZCUUETJJRC')
```

Other changes to note here is the use of `field()` to call our `generate_id()` function. The `default_factory` argument is where we specify what method will generate our id. Also, because our `id` now has a "default" value, we have to place it below all fields that do not have a default value defined. Here we've also removed the `id` from the initializer to create a new id by default and not require the user to provide an `id` - we do this by declaring `init=false` in the field definition.

[Learn more about Dataclass fields](https://docs.python.org/3/library/dataclasses.html#dataclasses.field)

```python
id: str = field(init=False, default_factory=generate_id)
```

For `email_addresses` we cannot simply declare `email_addresses: list[str] = []` because this will create an empty list that has the potential to be referenced by other functions - in other words, this list is now "open" for anyone to add elements to it. So instead, we use the `field(default_factory=list)` value. This is how we say "email_addresses is a list of email addresses."

```python
email_addresses: list[str] = field(default_factory=list)
```

For `search_string` we are wanting to create a string we can search a person by. This search string is derived from `name` and `address` but since we don't have these values yet; we are just declaring variables not executing; we have to move this to a `__post__init__()` method. This is essentially saying "capture the name and address values passed to our Person initializer  AND THEN create the search string."

We can remove the `search_string` from the string representation of our Person class by using `repr=False`; this just means we'll no longer see search_string in the terminal. And lastly, to declare that `search_string` is something that's internal to the class, we use the `_search_string` declaration.

```python
_search_string: str = field(init=False, repr=False)

    def __post_init__(self):
        self._search_string = f"{self.name} {self.address}"
```

### Dataclass Parameters

[Learn more about Dataclass Parameters](https://docs.python.org/3/library/dataclasses.html)

We also have the ability to ask the user to use key-word arguments when initializing a new Person by implementing the following:

Note that by default this is `false`

```python
@dataclass(kw_only=True)
class Person:
    name: str
    address: str
    active: bool = True
    email_addresses: list[str] = field(default_factory=list)
    id: str = field(init=False, default_factory=generate_id)
    _search_string: str = field(init=False, repr=False)
```

```python
person = Person(name="John", address="123 Main St")
```

Another thing we can do is not accept Person instanced modifications. We declare this by implementing the following:

Note that this results in a `dataclasses.FrozenInstanceError`. This `frozen` implementation can be very useful when working with data that should not be modified like Coordinates or `Master` data representations.

```python
@dataclass(frozen=True)
class Person:
    name: str
    address: str
    active: bool = True
    email_addresses: list[str] = field(default_factory=list)
    id: str = field(init=False, default_factory=generate_id)
    _search_string: str = field(init=False, repr=False)
```

One thing to note here is that our `_search_string` is no longer allowed since technically we are "modifying" our instance due to the `__post__init__()` call. So how can we implement `_search_string` on a `frozen` Dataclass? We use Properties!

### Unlocking the Power of Class Properties

What we begin by doing is creating a `@property` for our `search_string()`.

```python
@dataclass(frozen=True)
class Person:
    name: str
    address: str
    active: bool = True
    email_addresses: list[str] = field(default_factory=list)
    id: str = field(init=False, default_factory=generate_id)

    @property
    def search_string(self) -> str:
        return f"{self.name} {self.address}"
```

Executing our python file shows `search_string` is still available but now as a getter property.

```terminal
python person_dataclass.py
Person(name='John', address='123 Main St', active=True, email_addresses=[], id='JEWWITLAZWYW')
John 123 Main St
```

The "read-only" rule prevents us from declaring `person.search_string = "foo"`.

From ChatGPT:

```text
In Python, getter properties are a way to implement read-only attributes on a class. They allow you to define a method that acts like an attribute and is accessed like one, but the value is computed dynamically every time it's accessed. This is particularly useful when you want to compute the value of an attribute based on some other data or when you want to enforce some logic or validation upon attribute access.

Getter properties are typically implemented using the @property decorator in Python.
```

If we want to allow for our getter properties to be modifiable, we create a `@{property}.setter` for the property. Note here that our Dataclass CANNOT be frozen, otherwise our setter will not work.

For example, if we look at the `VideoClip` Dataclass in the `class_properties.py` file.

```python
@dataclass
class VideoClip:
    minutes: int
    seconds: int
    title: str

    @property
    def duration(self) -> int:
        return self.minutes * 60 + self.seconds

    @duration.setter
    def duration(self, seconds: int) -> None:
        self.minutes, self.seconds = divmod(seconds, 60)
```

The `@property` for `duration` will create a read only getter property that takes in the provided minutes and seconds from the user/initializer.

The `@duration.setter` gives us the ability to later declare `videoClip_Instance.duration  = 100` and the setter will take in the seconds provided and return it as that specific instance `self.minutes, self.seconds` properties. So basically, this duration setter is applying `divmod` logic and defining the values for minutes and seconds.

As shown in `class_properties.py`:

```python
clip1 = VideoClip(minutes=1, seconds=30, title="Clip 1")
...
clip1.duration = 120
```

### Understanding str vs repr dunder methods

`def __str__(self):`

This method is called by the `str()` function and is intended to return a human-readable string representation of the object. It's typically used for displaying information to end-users or for logging purposes. If the `__str__()` method is not defined for a class, Python will use the `__repr__()` method as a fallback.

So, if we want to add this `__str__(self)` dunder method to our Person Dataclass we implement the following:

```python
def __str__(self) -> str:
    return self.name
```

And if we run our python script, we see the str dunder method implemented because str overrides the repr dunder method.

```terminal
John
```

`def __repr__(self):`

This method is called by the `repr()` function and is meant to return an unambiguous string representation of the object, primarily for debugging and development purposes. It should ideally be a string that, when passed to the `eval()` function, would recreate the object. If possible, the string returned by `__repr__()` should be valid Python code. If `__repr__()` is not defined, Python will provide a default implementation based on the class name and memory address of the object.

We've seen how the `__str__` dunder method overrides the `__repr__` dunder method but we can still explicitly call this `__repr__` method by using the `repr()` function.

```python
print(repr(person_1))
```

Or, we can use an f-string with `!r` to execute the `__repr__` dunder method.

```python
print(f"{person1!r}")
```

### Improving the Performance of Accessing Class Members

From ChatGPT:

```text
In Python, the __slots__ attribute is a mechanism that allows you to explicitly declare the attributes (instance variables) a class can have. This can provide performance benefits in terms of memory usage and attribute access speed, especially for classes with a large number of instances.
```

```python
class MyClass:
    __slots__ = ('attribute1', 'attribute2')

    def __init__(self, attr1, attr2):
        self.attribute1 = attr1
        self.attribute2 = attr2

# Creating an instance of MyClass
obj = MyClass('value1', 'value2')

# Accessing attributes
print(obj.attribute1)
print(obj.attribute2)

# Trying to add a new attribute (will raise an AttributeError)
# obj.attribute3 = 'value3'
```

In other words, with `__slots__` we, the developer, are agreeing to have a fixed number of attributes which thus improves performance.

We can see this in action with a Dataclass implementation in the file - `Projects/NextLevelPython/slots_dataclass.py`.

If we run this file, we see how implementing slots improves performance for this mock `get_set_delete()` action.

```terminal
python slots_dataclass.py

No slots: 0.0973575840034755
Slots: 0.09308728600444738
% performance improvement: 4.39%
```

Why is this? Well,

```text
By default, Python uses a dynamic dictionary to store an object's instance variables, which allows for flexibility but can consume more memory and incur a slight performance overhead. However, when you define __slots__ for a class, Python uses a more compact internal representation, which does not include a dictionary, resulting in memory savings and faster attribute access.
```

One things to call out is the risk of inheritance and slot usage:

`__slots__` can affect subclassing. If a parent class defines `__slots__`, subclasses do not automatically inherit them. However, you can define `__slots__` in subclasses to extend or override the parent's slots. Also, we loose the ability to have dynamic attributes present in our Class.

## Next-Level Functions

### Callables and High-Order Functions

Remember: "Functions in Python are also called Callables."

Something to remember is that in Python everything is an Object and specifically, functions are objects of type `callable`. So, if we wanted to, we can create a `class` and implement a `__call__` dunder method. The main idea of the `__call__` method is to write a class and invoke it like a function. You can refer to it as "callable object."

In Python, a "higher-order function" is a fancy way of saying that a function can do one of two things:

1. Take another function as an argument: This means you can pass a function to another function as if it were a variable.

2. Return a function: The function can generate and give back another function as a result.

For this example, we will be working with the `Projects/NextLevelPython/func_param_lambda.py` file.

We first create a `Customer` Dataclass.

```python
@dataclass
class Customer:
    name: str
    age: int
```

And have a simple `send_email_promotion()` function that performs some `age` check on a list of Customers and checks whether this customer is eligible for promotion.

Our first `send_email_promotion()` logic looks like this:

```python
def send_email_promotion(customers: list[Customer]) -> None:
    for customer in customers:
        print(f"Checking {customer.name}")
        if customer.age > 50:
            print(f"{customer.name} is eligible for promotion")
        else:
            print(f"{customer.name} is not eligible for promotion")
```

We can improve this by creating a `is_eligible_for_promotion()` function that is called inside of our `send_email_promotion()` function.

```python
def is_eligible_for_promotion(custom: Customer) -> bool:
    return customer.age > 50
```

```python
def send_email_promotion(customers: list[Customer]) -> None:
    for customer in customers:
        print(f"Checking {customer.name}")
        if is_eligible_for_promotion(customer)
            print(f"{customer.name} is eligible for promotion")
        else:
            print(f"{customer.name} is not eligible for promotion")
```

This is good, but we still don't have the option of dynamically execute other "check" functions - hypothetically, what if we now wanted to create some sort of `is_eligible_for_sale()` check condition? We'd have to crate another function that checks this condition and then execute it in our `send_email_promotion()` function.

#### Refactor using Callable

So to improve our `send_email_promotion()` even more, we will pass our `is_eligible_{something}` function as an argument to our `send_email_promotion()` function. Specifically, we pass this as a `Callable`.

In the `Callable` type-hint, we also specify what object to accept as arguments and the return value of THIS callable. `is_eligible: Callable[[Customer], bool]`.

```python
def send_email_promotion(
    customers: list[Customer], is_eligible: Callable[[Customer], bool]
) -> None:
    for customer in customers:
        print(f"Checking {customer.name}")
        if is_eligible(customer):
            print(f"{customer.name} is eligible for promotion")
        else:
            print(f"{customer.name} is not eligible for promotion")
```

Now, to call our `send_email_promotion()` function with this new `Callable` argument we apply the following:

```python
send_email_promotion(customers, is_eligible_for_promotion)
```

What happened here?

The introduction of our Callable `is_eligible` is a place holder that we can use to pass dynamically other function to our `send_email_promotion()` process.

#### Refactor using Lambda Function

Another option we have is to use a `lambda` function instead of explicitly creating a `is_eligible_for_promotion()` function.

```python
send_email_promotion(customers, lambda customer: customer.age > 50)
```

Here, our `lambda` is our `is_eligible` Callable so we can use the `customer` variable because we have access to the `Customer` object as defined in our type-hint. We could also have used `i` or `person` but `customer` is the variable that makes the most sense.

This type of callable implementation with `lambda` gives us the ability to quickly change conditions without having to create a new function definition for a simple check like `customer.age > 50`.

### Partial Function Application

Note: The file for this example is `Projects/NextLevelPython/partial_func_application.py`.

So, we see how we can use a lambda to change the `age` our check is based on but there is another way we can achieve this and that's with using "Partial Functions" ; `from functools import partial`.

In more technical terms, with partial functions we are changing the signature header of a function by already supplying some argument values.

```text
Function Header: specifies the name of the function, and any arguments (inputs, or parameters) into the function.
```

From ChatGPT:

```text
Partial function application in Python is a way to create new functions by fixing some of the arguments of an existing function.
```

```python
from functools import partial

def add(x, y):
    return x + y

add_five = partial(add, 5)
result = add_five(10)  # This will give you 15 (10 + 5)


# Note: add_five is a new function that takes only one argument (because the x is already fixed to 5) and adds 5 to whatever number you give it.

```

We first start by adding a new argument to our `is_eligible_for_promotion` function that will allow us to pass whatever age we want removing the hard-codded 50.

```python
def is_eligible_for_promotion(customer: Customer, cutoff_age: int) -> bool:
    return customer.age > cutoff_age
```

But now, this new `is_eligible_for_promotion()` function does not adhere to our `is_eligible: Callable[[Customer], bool]` Callable because there is this extra argument we need to pass - `cutoff_age`.

To fix this, we use partial function application to build a new function that then becomes our callable to pass to `send_email_promotion()`. One thing to remember here is that this `functools.partial()` returns a function i.e a Callable.

```python
is_eligible_60 = functools.partial(
        is_eligible_for_promotion, cutoff_age=60)
send_email_promotion(customers, is_eligible_60)
```

### Cached Properties

Note: The file for this example is `Projects/NextLevelPython/cached_properties.py`

[Python Documentation](https://docs.python.org/3/library/functools.html#functools.cached_property)

From ChatGPT:

```text
Cached properties in Python are a way to improve the performance of code by caching the result of a method call, so that subsequent calls with the same arguments don't have to recompute the result. This is particularly useful when the method involves heavy computation or accessing external resources.
```

In this example, we are calculating the standard deviation of a data set but caching it so that each time we call this standard deviation we don't recompute and get improved performance.

```python
import statistics
from functools import cached_property
from typing import Iterable


class DataSet:
    def __init__(self, sequence_of_numbers: Iterable[float]):
        self._data = tuple(sequence_of_numbers)

    @cached_property
    def stdev(self):
        print("Computing stdev...")
        return statistics.stdev(self._data)
```

#### Why did we use a tuple?

1. Immutability: Tuples are immutable, meaning once created, their contents cannot be changed. This ensures that the data stored in _data remains consistent throughout the lifetime of the DataSet instance. It prevents accidental modification of the data, which can be crucial for maintaining data integrity, especially in scenarios where the DataSet instance is passed around or shared between different parts of a program.

2. Efficient Access: Tuples are generally more efficient for accessing elements compared to other iterable data structures like lists. Since tuples are immutable, their internal structure can be optimized for faster access. This can be beneficial if the DataSet instance is used in performance-critical scenarios, such as large-scale data processing or numerical computations.

We can see this caching in action by running our python file and noticing how the "Computing stdev..." message is only being executed once.

```terminal
python cached_properties.py

Computing stdev...
1.5811388300841898
1.5811388300841898
1.5811388300841898
```

If we compare this to a "normal" `@property` we see how the standard deviation is being re-calculated on each run.

```python
@property
    def stdev(self):
        print("Computing stdev...")
        return statistics.stdev(self._data)
```

```terminal
python cached_properties.py

Computing stdev...
1.5811388300841898
Computing stdev...
1.5811388300841898
Computing stdev...
1.5811388300841898
```

### Single Dispatch

Note: The file for this example is `Projects/NextLevelPython/single_dispatch.py`

From ChatGPT:

```text
Single dispatch is a feature in Python that allows you to define a function differently based on the type of the first argument. This means that you can have multiple implementations of a function, each tailored to handle a specific type of input.
```

The process of using single dispatch is to first define a "default" function and then register varieties of this default function that handle different data types.

```python
from functools import singledispatch
from typing import Any


@singledispatch
def add(x: int, y: int) -> int:
    return x + y


@add.register
def _(x: str, y: str) -> int:
    return f"{x} {y}"
```

```terminal
python single_dispatch.py

3
Hello World
```

#### Doing the same but with Type Inspection

```python
def add(x, y):
    if isinstance(x, int) and isinstance(y, int):
        return x + y
    elif isinstance(x, str) and isinstance(y, str):
        return x + y
    else:
        raise TypeError("Unsupported type combination")

# Test cases
print(add(5, 3))       # Output: 8 (integer addition)
print(add("hello", " world"))   # Output: hello world (string concatenation)
```

## Concurrent Programming
